{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _check_data(X):\n",
    "    \"\"\"Check data is numpy array and has the proper dimensions.\"\"\"\n",
    "    if not isinstance(X, (np.ndarray, list)):\n",
    "        raise AttributeError('data should be a list or a numpy array')\n",
    "\n",
    "    dtype = np.complex128 if np.any(np.iscomplex(X)) else np.float64\n",
    "    X = np.asanyarray(X, dtype=dtype)\n",
    "    if X.ndim > 3:\n",
    "        raise ValueError('Data must be 3D at most')\n",
    "\n",
    "    return X\n",
    "\n",
    "def theshapeof(X):\n",
    "    \"\"\"Return the shape of X.\"\"\"\n",
    "    X = _check_data(X)\n",
    "    # if not isinstance(X, np.ndarray):\n",
    "    #     raise AttributeError('X must be a numpy array')\n",
    "\n",
    "    if X.ndim == 3:\n",
    "        return X.shape[0], X.shape[1], X.shape[2]\n",
    "    elif X.ndim == 2:\n",
    "        return X.shape[0], X.shape[1], 1\n",
    "    elif X.ndim == 1:\n",
    "        return X.shape[0], 1, 1\n",
    "    else:\n",
    "        raise ValueError(\"Array contains more than 3 dimensions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"TRCA utils.\"\"\"\n",
    "import numpy as np\n",
    "\n",
    "from scipy.signal import filtfilt, cheb1ord, cheby1\n",
    "from scipy import stats\n",
    "\n",
    "\n",
    "def round_half_up(num, decimals=0):\n",
    "    \"\"\"Round half up round the last decimal of the number.\n",
    "\n",
    "    The rules are:\n",
    "    from 0 to 4 rounds down\n",
    "    from 5 to 9 rounds up\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    num : float\n",
    "        Number to round\n",
    "    decimals : number of decimals\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    num rounded\n",
    "    \"\"\"\n",
    "    multiplier = 10 ** decimals\n",
    "    return int(np.floor(num * multiplier + 0.5) / multiplier)\n",
    "\n",
    "\n",
    "def normfit(data, ci=0.95):\n",
    "    \"\"\"Compute the mean, std and confidence interval for them.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    data : array, shape=()\n",
    "        Input data.\n",
    "    ci : float\n",
    "        Confidence interval (default=0.95).\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    m : float\n",
    "        Mean.\n",
    "    sigma : float\n",
    "        Standard deviation\n",
    "    [m - h, m + h] : list\n",
    "        Confidence interval of the mean.\n",
    "    [sigmaCI_lower, sigmaCI_upper] : list\n",
    "        Confidence interval of the std.\n",
    "    \"\"\"\n",
    "    arr = 1.0 * np.array(data)\n",
    "    num = len(arr)\n",
    "    avg, std_err = np.mean(arr), stats.sem(arr)\n",
    "    h_int = std_err * stats.t.ppf((1 + ci) / 2., num - 1)\n",
    "    var = np.var(data, ddof=1)\n",
    "    var_ci_upper = var * (num - 1) / stats.chi2.ppf((1 - ci) / 2, num - 1)\n",
    "    var_ci_lower = var * (num - 1) / stats.chi2.ppf(1 - (1 - ci) / 2, num - 1)\n",
    "    sigma = np.sqrt(var)\n",
    "    sigma_ci_lower = np.sqrt(var_ci_lower)\n",
    "    sigma_ci_upper = np.sqrt(var_ci_upper)\n",
    "\n",
    "    return avg, sigma, [avg - h_int, avg +\n",
    "                        h_int], [sigma_ci_lower, sigma_ci_upper]\n",
    "\n",
    "\n",
    "def itr(n, p, t):\n",
    "    \"\"\"Compute information transfer rate (ITR).\n",
    "\n",
    "    Definition in [1]_.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    n : int\n",
    "        Number of targets.\n",
    "    p : float\n",
    "        Target identification accuracy (0 <= p <= 1).\n",
    "    t : float\n",
    "        Average time for a selection (s).\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    itr : float\n",
    "        Information transfer rate [bits/min]\n",
    "\n",
    "    References\n",
    "    ----------\n",
    "    .. [1] M. Cheng, X. Gao, S. Gao, and D. Xu,\n",
    "        \"Design and Implementation of a Brain-Computer Interface With High\n",
    "        Transfer Rates\", IEEE Trans. Biomed. Eng. 49, 1181-1186, 2002.\n",
    "\n",
    "    \"\"\"\n",
    "    itr = 0\n",
    "\n",
    "    if (p < 0 or 1 < p):\n",
    "        raise ValueError('Accuracy need to be between 0 and 1.')\n",
    "    elif (p < 1 / n):\n",
    "        itr = 0\n",
    "        raise ValueError('ITR might be incorrect because accuracy < chance')\n",
    "    elif (p == 1):\n",
    "        itr = np.log2(n) * 60 / t\n",
    "    else:\n",
    "        itr = (np.log2(n) + p * np.log2(p) + (1 - p) *\n",
    "               np.log2((1 - p) / (n - 1))) * 60 / t\n",
    "\n",
    "    return itr\n",
    "\n",
    "\n",
    "def bandpass(eeg, sfreq, Wp, Ws):\n",
    "    \"\"\"Filter bank design for decomposing EEG data into sub-band components.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    eeg : np.array, shape=(n_samples, n_chans[, n_trials])\n",
    "        Training data.\n",
    "    sfreq : int\n",
    "        Sampling frequency of the data.\n",
    "    Wp : 2-tuple\n",
    "        Passband for Chebyshev filter.\n",
    "    Ws : 2-tuple\n",
    "        Stopband for Chebyshev filter.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    y: np.array, shape=(n_trials, n_chans, n_samples)\n",
    "        Sub-band components decomposed by a filter bank.\n",
    "\n",
    "    See Also\n",
    "    --------\n",
    "    scipy.signal.cheb1ord :\n",
    "        Chebyshev type I filter order selection.\n",
    "\n",
    "    \"\"\"\n",
    "    # Chebyshev type I filter order selection.\n",
    "    N, Wn = cheb1ord(Wp, Ws, 3, 40, fs=sfreq)\n",
    "\n",
    "    # Chebyshev type I filter design\n",
    "    B, A = cheby1(N, 0.5, Wn, btype=\"bandpass\", fs=sfreq)\n",
    "\n",
    "    # the arguments 'axis=0, padtype='odd', padlen=3*(max(len(B),len(A))-1)'\n",
    "    # correspond to Matlab filtfilt : https://dsp.stackexchange.com/a/47945\n",
    "    y = filtfilt(B, A, eeg, axis=0, padtype='odd',\n",
    "                 padlen=3 * (max(len(B), len(A)) - 1))\n",
    "    return y\n",
    "\n",
    "\n",
    "def schaefer_strimmer_cov(X):\n",
    "    r\"\"\"Schaefer-Strimmer covariance estimator.\n",
    "\n",
    "    Shrinkage estimator described in [1]_:\n",
    "\n",
    "    .. math:: \\hat{\\Sigma} = (1 - \\gamma)\\Sigma_{scm} + \\gamma T\n",
    "\n",
    "    where :math:`T` is the diagonal target matrix:\n",
    "\n",
    "    .. math:: T_{i,j} = \\{ \\Sigma_{scm}^{ii} \\text{if} i = j,\n",
    "         0 \\text{otherwise} \\}\n",
    "\n",
    "    Note that the optimal :math:`\\gamma` is estimated by the authors' method.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    X: array, shape=(n_chans, n_samples)\n",
    "        Signal matrix.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    cov: array, shape=(n_chans, n_chans)\n",
    "        Schaefer-Strimmer shrinkage covariance matrix.\n",
    "\n",
    "    References\n",
    "    ----------\n",
    "    .. [1] Schafer, J., and K. Strimmer. 2005. A shrinkage approach to\n",
    "       large-scale covariance estimation and implications for functional\n",
    "       genomics. Statist. Appl. Genet. Mol. Biol. 4:32.\n",
    "    \"\"\"\n",
    "    ns = X.shape[1]\n",
    "    C_scm = np.cov(X, ddof=0)\n",
    "    X_c = X - np.tile(X.mean(axis=1), [ns, 1]).T\n",
    "\n",
    "    # Compute optimal gamma, the weigthing between SCM and srinkage estimator\n",
    "    R = ns / (ns - 1.0) * np.corrcoef(X)\n",
    "    var_R = (X_c ** 2).dot((X_c ** 2).T) - 2 * C_scm * X_c.dot(X_c.T)\n",
    "    var_R += ns * C_scm ** 2\n",
    "\n",
    "    var_R = ns / ((ns - 1) ** 3 * np.outer(X.var(1), X.var(1))) * var_R\n",
    "    R -= np.diag(np.diag(R))\n",
    "    var_R -= np.diag(np.diag(var_R))\n",
    "    gamma = max(0, min(1, var_R.sum() / (R ** 2).sum()))\n",
    "\n",
    "    cov = (1. - gamma) * (ns / (ns - 1.)) * C_scm\n",
    "    cov += gamma * (ns / (ns - 1.)) * np.diag(np.diag(C_scm))\n",
    "\n",
    "    return cov\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Task-Related Component Analysis.\"\"\"\n",
    "# Authors: Giuseppe Ferraro <giuseppe.ferraro@isae-supaero.fr>\n",
    "#          Ludovic Darmet <ludovic.darmet@isae-supaero.fr>\n",
    "import numpy as np\n",
    "import scipy.linalg as linalg\n",
    "from pyriemann.utils.mean import mean_covariance\n",
    "from pyriemann.estimation import Covariances\n",
    "\n",
    "class TRCA:\n",
    "    \"\"\"Task-Related Component Analysis (TRCA).\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    sfreq : float\n",
    "        Sampling rate.\n",
    "    filterbank : list[[2-tuple, 2-tuple]]\n",
    "        Filterbank frequencies. Each list element is itself a list of passband\n",
    "        `Wp` and stopband `Ws` edges frequencies `[Wp, Ws]`. For example, this\n",
    "        creates 3 bands, starting at 6, 14, and 22 hz respectively::\n",
    "\n",
    "            [[(6, 90), (4, 100)],\n",
    "             [(14, 90), (10, 100)],\n",
    "             [(22, 90), (16, 100)]]\n",
    "\n",
    "        See :func:`scipy.signal.cheb1ord()` for more information on how to\n",
    "        specify the `Wp` and `Ws`.\n",
    "    ensemble : bool\n",
    "        If True, perform the ensemble TRCA analysis (default=False).\n",
    "    method : str in {'original'| 'riemann'}\n",
    "        Use original implementation from [1]_ or a variation that uses\n",
    "        regularization and the geodesic mean [2]_.\n",
    "    regularization : str in {'schaefer' | 'lwf' | 'oas' | 'scm'}\n",
    "        Regularization estimator used for covariance estimation with the\n",
    "        `riemann` method. Consider 'schaefer', 'lwf', 'oas'. 'scm' does not add\n",
    "        regularization and is almost equivalent to the original implementation.\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    traindata : array, shape=(n_bands, n_chans, n_trials)\n",
    "        Reference (training) data decomposed into sub-band components by the\n",
    "        filter bank analysis.\n",
    "    y_train : array, shape=(n_trials)\n",
    "        Labels associated with the train data.\n",
    "    coef_ : array, shape=(n_chans, n_chans)\n",
    "        Weight coefficients for electrodes which can be used as a spatial\n",
    "        filter.\n",
    "    classes : list\n",
    "        Classes.\n",
    "    n_bands : int\n",
    "        Number of sub-bands.\n",
    "\n",
    "    References\n",
    "    ----------\n",
    "    .. [1] M. Nakanishi, Y. Wang, X. Chen, Y. -T. Wang, X. Gao, and T.-P. Jung,\n",
    "       \"Enhancing detection of SSVEPs for a high-speed brain speller using\n",
    "       task-related component analysis\", IEEE Trans. Biomed. Eng,\n",
    "       65(1):104-112, 2018.\n",
    "    .. [2] Barachant, A., Bonnet, S., Congedo, M., & Jutten, C. (2010,\n",
    "       October). Common spatial pattern revisited by Riemannian geometry. In\n",
    "       2010 IEEE International Workshop on Multimedia Signal Processing (pp.\n",
    "       472-476). IEEE.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, sfreq, filterbank, ensemble=False, method='original',\n",
    "                 estimator='scm'):\n",
    "        self.sfreq = sfreq\n",
    "        self.ensemble = ensemble\n",
    "        self.filterbank = filterbank\n",
    "        self.n_bands = len(self.filterbank)\n",
    "        self.coef_ = None\n",
    "        self.method = method\n",
    "        if estimator == 'schaefer':\n",
    "            self.estimator = schaefer_strimmer_cov\n",
    "        else:\n",
    "            self.estimator = estimator\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        \"\"\"Training stage of the TRCA-based SSVEP detection.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : array, shape=(n_samples, n_chans[, n_trials])\n",
    "            Training EEG data.\n",
    "        y : array, shape=(trials,)\n",
    "            True label corresponding to each trial of the data array.\n",
    "\n",
    "        \"\"\"\n",
    "        n_samples, n_chans, _ = theshapeof(X)\n",
    "        classes = np.unique(y)\n",
    "\n",
    "        trains = np.zeros((len(classes), self.n_bands, n_samples, n_chans))\n",
    "\n",
    "        W = np.zeros((self.n_bands, len(classes), n_chans))\n",
    "\n",
    "        for class_i in classes:\n",
    "            # Select data with a specific label\n",
    "            print(\"Here the class is \", class_i)\n",
    "            eeg_tmp = X[..., y == class_i]\n",
    "            for fb_i in range(self.n_bands):\n",
    "                # Filter the signal with fb_i\n",
    "                eeg_tmp = bandpass(eeg_tmp, self.sfreq,\n",
    "                                   Wp=self.filterbank[fb_i][0],\n",
    "                                   Ws=self.filterbank[fb_i][1])\n",
    "                if (eeg_tmp.ndim == 3):\n",
    "                    # Compute mean of the signal across trials\n",
    "                    trains[class_i, fb_i] = np.mean(eeg_tmp, -1)\n",
    "                else:\n",
    "                    trains[class_i, fb_i] = eeg_tmp\n",
    "                # Find the spatial filter for the corresponding filtered signal\n",
    "                # and label\n",
    "                if self.method == 'original':\n",
    "                    w_best = trca(eeg_tmp)\n",
    "                elif self.method == 'riemann':\n",
    "                    w_best = trca_regul(eeg_tmp, self.estimator)\n",
    "                else:\n",
    "                    raise ValueError('Invalid `method` option.')\n",
    "\n",
    "                W[fb_i, class_i, :] = w_best  # Store the spatial filter\n",
    "\n",
    "        self.trains = trains\n",
    "        self.coef_ = W\n",
    "        self.classes = classes\n",
    "\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"Test phase of the TRCA-based SSVEP detection.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X: array, shape=(n_samples, n_chans[, n_trials])\n",
    "            Test data.\n",
    "        model: dict\n",
    "            Fitted model to be used in testing phase.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        pred: np.array, shape (trials)\n",
    "            The target estimated by the method.\n",
    "\n",
    "        \"\"\"\n",
    "        if self.coef_ is None:\n",
    "            raise RuntimeError('TRCA is not fitted')\n",
    "\n",
    "        # Alpha coefficients for the fusion of filterbank analysis\n",
    "        fb_coefs = [(x + 1)**(-1.25) + 0.25 for x in range(self.n_bands)]\n",
    "        _, _, n_trials = theshapeof(X)\n",
    "\n",
    "        r = np.zeros((self.n_bands, len(self.classes)))\n",
    "        pred = np.zeros((n_trials), 'int')  # To store predictions\n",
    "\n",
    "        for trial in range(n_trials):\n",
    "            test_tmp = X[..., trial]  # pick a trial to be analysed\n",
    "            for fb_i in range(self.n_bands):\n",
    "\n",
    "                # filterbank on testdata\n",
    "                testdata = bandpass(test_tmp, self.sfreq,\n",
    "                                    Wp=self.filterbank[fb_i][0],\n",
    "                                    Ws=self.filterbank[fb_i][1])\n",
    "\n",
    "                for class_i in self.classes:\n",
    "                    # Retrieve reference signal for class i\n",
    "                    # (shape: n_chans, n_samples)\n",
    "                    traindata = np.squeeze(self.trains[class_i, fb_i])\n",
    "                    if self.ensemble:\n",
    "                        # shape = (n_chans, n_classes)\n",
    "                        w = np.squeeze(self.coef_[fb_i]).T\n",
    "                    else:\n",
    "                        # shape = (n_chans)\n",
    "                        w = np.squeeze(self.coef_[fb_i, class_i])\n",
    "\n",
    "                    # Compute 2D correlation of spatially filtered test data\n",
    "                    # with ref\n",
    "                    r_tmp = np.corrcoef((testdata @ w).flatten(),\n",
    "                                        (traindata @ w).flatten())\n",
    "                    r[fb_i, class_i] = r_tmp[0, 1]\n",
    "\n",
    "            rho = np.dot(fb_coefs, r)  # fusion for the filterbank analysis\n",
    "\n",
    "            tau = np.argmax(rho)  # retrieving index of the max\n",
    "            pred[trial] = int(tau)\n",
    "\n",
    "        return pred\n",
    "\n",
    "\n",
    "def trca(X):\n",
    "    \"\"\"Task-related component analysis.\n",
    "\n",
    "    This function implements the method described in [1]_.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    X : array, shape=(n_samples, n_chans[, n_trials])\n",
    "        Training data.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    W : array, shape=(n_chans,)\n",
    "        Weight coefficients for electrodes which can be used as a spatial\n",
    "        filter.\n",
    "\n",
    "    References\n",
    "    ----------\n",
    "    .. [1] M. Nakanishi, Y. Wang, X. Chen, Y. -T. Wang, X. Gao, and T.-P. Jung,\n",
    "       \"Enhancing detection of SSVEPs for a high-speed brain speller using\n",
    "       task-related component analysis\", IEEE Trans. Biomed. Eng,\n",
    "       65(1):104-112, 2018.\n",
    "\n",
    "    \"\"\"\n",
    "    n_samples, n_chans, n_trials = theshapeof(X)\n",
    "\n",
    "    # 1. Compute empirical covariance of all data (to be bounded)\n",
    "    # -------------------------------------------------------------------------\n",
    "    # Concatenate all the trials to have all the data as a sequence\n",
    "    UX = np.zeros((n_chans, n_samples * n_trials))\n",
    "    for trial in range(n_trials):\n",
    "        UX[:, trial * n_samples:(trial + 1) * n_samples] = X[..., trial].T\n",
    "\n",
    "    # Mean centering\n",
    "    UX -= np.mean(UX, 1)[:, None]\n",
    "\n",
    "    # Covariance\n",
    "    Q = UX @ UX.T\n",
    "\n",
    "    # 2. Compute average empirical covariance between all pairs of trials\n",
    "    # -------------------------------------------------------------------------\n",
    "    S = np.zeros((n_chans, n_chans))\n",
    "    for trial_i in range(n_trials - 1):\n",
    "        x1 = np.squeeze(X[..., trial_i])\n",
    "\n",
    "        # Mean centering for the selected trial\n",
    "        x1 -= np.mean(x1, 0)\n",
    "\n",
    "        # Select a second trial that is different\n",
    "        for trial_j in range(trial_i + 1, n_trials):\n",
    "            x2 = np.squeeze(X[..., trial_j])\n",
    "\n",
    "            # Mean centering for the selected trial\n",
    "            x2 -= np.mean(x2, 0)\n",
    "\n",
    "            # Compute empirical covariance between the two selected trials and\n",
    "            # sum it\n",
    "            S = S + x1.T @ x2 + x2.T @ x1\n",
    "\n",
    "    # 3. Compute eigenvalues and vectors\n",
    "    # -------------------------------------------------------------------------\n",
    "    lambdas, W = linalg.eig(S, Q, left=True, right=False)\n",
    "\n",
    "    # Select the eigenvector corresponding to the biggest eigenvalue\n",
    "    W_best = W[:, np.argmax(lambdas)]\n",
    "\n",
    "    return W_best\n",
    "\n",
    "\n",
    "def trca_regul(X, method):\n",
    "    \"\"\"Task-related component analysis.\n",
    "\n",
    "    This function implements a variation of the method described in [1]_. It is\n",
    "    inspired by a riemannian geometry approach to CSP [2]_. It adds\n",
    "    regularization to the covariance matrices and uses the riemannian mean for\n",
    "    the inter-trial covariance matrix `S`.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    X : array, shape=(n_samples, n_chans[, n_trials])\n",
    "        Training data.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    W : array, shape=(n_chans,)\n",
    "        Weight coefficients for electrodes which can be used as a spatial\n",
    "        filter.\n",
    "\n",
    "    References\n",
    "    ----------\n",
    "    .. [1] M. Nakanishi, Y. Wang, X. Chen, Y. -T. Wang, X. Gao, and T.-P. Jung,\n",
    "       \"Enhancing detection of SSVEPs for a high-speed brain speller using\n",
    "       task-related component analysis\", IEEE Trans. Biomed. Eng,\n",
    "       65(1):104-112, 2018.\n",
    "    .. [2] Barachant, A., Bonnet, S., Congedo, M., & Jutten, C. (2010,\n",
    "       October). Common spatial pattern revisited by Riemannian geometry. In\n",
    "       2010 IEEE International Workshop on Multimedia Signal Processing (pp.\n",
    "       472-476). IEEE.\n",
    "\n",
    "    \"\"\"\n",
    "    n_samples, n_chans, n_trials = theshapeof(X)\n",
    "\n",
    "    # 1. Compute empirical covariance of all data (to be bounded)\n",
    "    # -------------------------------------------------------------------------\n",
    "    # Concatenate all the trials to have all the data as a sequence\n",
    "    UX = np.zeros((n_chans, n_samples * n_trials))\n",
    "    for trial in range(n_trials):\n",
    "        UX[:, trial * n_samples:(trial + 1) * n_samples] = X[..., trial].T\n",
    "\n",
    "    # Mean centering\n",
    "    UX -= np.mean(UX, 1)[:, None]\n",
    "\n",
    "    # Compute empirical variance of all data (to be bounded)\n",
    "    cov = Covariances(estimator=method).fit_transform(UX[np.newaxis, ...])\n",
    "    Q = np.squeeze(cov)\n",
    "\n",
    "    # 2. Compute average empirical covariance between all pairs of trials\n",
    "    # -------------------------------------------------------------------------\n",
    "    # Intertrial correlation computation\n",
    "    data = np.concatenate((X, X), axis=1)\n",
    "\n",
    "    # Swapaxes to fit pyriemann Covariances\n",
    "    data = np.swapaxes(data, 0, 2)\n",
    "    cov = Covariances(estimator=method).fit_transform(data)\n",
    "\n",
    "    # Keep only inter-trial\n",
    "    S = cov[:, :n_chans, n_chans:] + cov[:, n_chans:, :n_chans]\n",
    "\n",
    "    # If the number of samples is too big, we compute an approximate of\n",
    "    # riemannian mean to speed up the computation\n",
    "    if n_trials < 30:\n",
    "        S = mean_covariance(S, metric='riemann')\n",
    "    else:\n",
    "        S = mean_covariance(S, metric='logeuclid')\n",
    "\n",
    "    # 3. Compute eigenvalues and vectors\n",
    "    # -------------------------------------------------------------------------\n",
    "    lambdas, W = linalg.eig(S, Q, left=True, right=False)\n",
    "\n",
    "    # Select the eigenvector corresponding to the biggest eigenvalue\n",
    "    W_best = W[:, np.argmax(lambdas)]\n",
    "\n",
    "    return W_best\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opening raw data file C:\\Users\\bci\\Documents\\projects\\hybrid-ssvep-p300-speller\\wang_experiment\\record\\sunsun_20230331_online\\sunsun_20230331_online.fif...\n",
      "    Range : 0 ... 119868 =      0.000 ...   479.472 secs\n",
      "Ready.\n",
      "Reading 0 ... 119868  =      0.000 ...   479.472 secs...\n",
      "Setting up band-stop filter\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandstop filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower transition bandwidth: 1.50 Hz\n",
      "- Upper transition bandwidth: 1.50 Hz\n",
      "- Filter length: 551 samples (2.204 sec)\n",
      "\n",
      "Creating RawArray with float64 data, n_channels=9, n_times=114869\n",
      "    Range : 0 ... 114868 =      0.000 ...   459.472 secs\n",
      "Ready.\n",
      "45 events found\n",
      "Event IDs: [1 2 3 4 5 6 7 8 9]\n",
      "Not setting metadata\n",
      "45 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 45 events and 125 original time points ...\n",
      "0 bad epochs dropped\n",
      "Using data from preloaded Raw for 45 events and 125 original time points ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bci\\AppData\\Local\\Temp\\ipykernel_12496\\3519179715.py:5: RuntimeWarning: This filename (C:\\Users\\bci\\Documents\\projects\\hybrid-ssvep-p300-speller\\wang_experiment\\record\\sunsun_20230331_online\\sunsun_20230331_online.fif) does not conform to MNE naming conventions. All raw files should end with raw.fif, raw_sss.fif, raw_tsss.fif, _meg.fif, _eeg.fif, _ieeg.fif, raw.fif.gz, raw_sss.fif.gz, raw_tsss.fif.gz, _meg.fif.gz, _eeg.fif.gz or _ieeg.fif.gz\n",
      "  raw =  mne.io.read_raw_fif(fname,  preload = True)\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:    0.0s finished\n"
     ]
    }
   ],
   "source": [
    "import mne\n",
    "\n",
    "\n",
    "fname = r\"C:\\Users\\bci\\Documents\\projects\\hybrid-ssvep-p300-speller\\wang_experiment\\record\\sunsun_20230331_online\\sunsun_20230331_online.fif\"\n",
    "raw =  mne.io.read_raw_fif(fname,  preload = True)\n",
    "raw.notch_filter([50,100], trans_bandwidth = 3)\n",
    "# raw.filter(5, 90, l_trans_bandwidth=2,h_trans_bandwidth=5,\n",
    "#         phase='zero-double')\n",
    "new_data = raw.get_data()[:,10*250:-10*250]\n",
    "raw_new = mne.io.RawArray(new_data, raw.info)\n",
    "montage = mne.channels.make_standard_montage('standard_1020')\n",
    "raw_new.set_montage(montage)\n",
    "events = mne.find_events(raw_new)\n",
    "epochs = mne.Epochs(raw=raw_new,events=events, baseline=None, tmin=0.14, tmax=0.64 - 1/250, reject=None, reject_by_annotation=False)\n",
    "data = epochs.get_data() \n",
    "X = epochs.get_data()[:, :-1, :] * 1e-6  # micro-volt default\n",
    "y = epochs.events[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(31,)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# (sample, channels, trials)\n",
    "\n",
    "X_train = np.transpose(X_train, (2, 1, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here the class is  1\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'TRCA' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[35], line 13\u001b[0m\n\u001b[0;32m      9\u001b[0m is_ensemble \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m     11\u001b[0m trca \u001b[39m=\u001b[39m TRCA(sfreq, filterbank, is_ensemble)\n\u001b[1;32m---> 13\u001b[0m trca\u001b[39m.\u001b[39;49mfit(X_train, y_train)\n",
      "Cell \u001b[1;32mIn[26], line 113\u001b[0m, in \u001b[0;36mTRCA.fit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    110\u001b[0m \u001b[39m# Find the spatial filter for the corresponding filtered signal\u001b[39;00m\n\u001b[0;32m    111\u001b[0m \u001b[39m# and label\u001b[39;00m\n\u001b[0;32m    112\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmethod \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39moriginal\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m--> 113\u001b[0m     w_best \u001b[39m=\u001b[39m trca(eeg_tmp)\n\u001b[0;32m    114\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmethod \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mriemann\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[0;32m    115\u001b[0m     w_best \u001b[39m=\u001b[39m trca_regul(eeg_tmp, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mestimator)\n",
      "\u001b[1;31mTypeError\u001b[0m: 'TRCA' object is not callable"
     ]
    }
   ],
   "source": [
    "sfreq = 250\n",
    "filterbank = [[(6, 90), (4, 100)],  # passband, stopband freqs [(Wp), (Ws)]\n",
    "              [(14, 90), (10, 100)],\n",
    "              [(22, 90), (16, 100)],\n",
    "              [(30, 90), (24, 100)],\n",
    "              [(38, 90), (32, 100)],\n",
    "              [(46, 90), (40, 100)],\n",
    "              [(54, 90), (48, 100)]]\n",
    "is_ensemble = True\n",
    "\n",
    "trca = TRCA(sfreq, filterbank, is_ensemble)\n",
    "\n",
    "trca.fit(X_train, y_train)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hybrid-ssvep-p300-speller-ZL_XZSnA",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
